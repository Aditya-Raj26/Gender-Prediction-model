{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F4hCiKc6NvGh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('gender-classifier.csv', encoding='latin-1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "p97vRYLAUQ5r",
        "outputId": "bcbf5723-32a1-4e18-e201-254caadf7c34"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3bc24e9f-7a0f-4bb3-8cf8-12415475d633\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_unit_id</th>\n",
              "      <th>_golden</th>\n",
              "      <th>_unit_state</th>\n",
              "      <th>_trusted_judgments</th>\n",
              "      <th>_last_judgment_at</th>\n",
              "      <th>gender</th>\n",
              "      <th>gender:confidence</th>\n",
              "      <th>profile_yn</th>\n",
              "      <th>profile_yn:confidence</th>\n",
              "      <th>created</th>\n",
              "      <th>...</th>\n",
              "      <th>profileimage</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>sidebar_color</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_count</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>815719226</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>10/26/15 23:24</td>\n",
              "      <td>male</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12/5/13 1:48</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/414342229...</td>\n",
              "      <td>0</td>\n",
              "      <td>FFFFFF</td>\n",
              "      <td>Robbie E Responds To Critics After Win Against...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>110964</td>\n",
              "      <td>10/26/15 12:40</td>\n",
              "      <td>6.587300e+17</td>\n",
              "      <td>main; @Kan1shk3</td>\n",
              "      <td>Chennai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>815719227</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>10/26/15 23:30</td>\n",
              "      <td>male</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10/1/12 13:51</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/539604221...</td>\n",
              "      <td>0</td>\n",
              "      <td>C0DEED</td>\n",
              "      <td>ÛÏIt felt like they were my friends and I was...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7471</td>\n",
              "      <td>10/26/15 12:40</td>\n",
              "      <td>6.587300e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>815719228</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>10/26/15 23:33</td>\n",
              "      <td>male</td>\n",
              "      <td>0.6625</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11/28/14 11:30</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/657330418...</td>\n",
              "      <td>1</td>\n",
              "      <td>C0DEED</td>\n",
              "      <td>i absolutely adore when louis starts the songs...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5617</td>\n",
              "      <td>10/26/15 12:40</td>\n",
              "      <td>6.587300e+17</td>\n",
              "      <td>clcncl</td>\n",
              "      <td>Belgrade</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>815719229</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>10/26/15 23:10</td>\n",
              "      <td>male</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6/11/09 22:39</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/259703936...</td>\n",
              "      <td>0</td>\n",
              "      <td>C0DEED</td>\n",
              "      <td>Hi @JordanSpieth - Looking at the url - do you...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1693</td>\n",
              "      <td>10/26/15 12:40</td>\n",
              "      <td>6.587300e+17</td>\n",
              "      <td>Palo Alto, CA</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>815719230</td>\n",
              "      <td>False</td>\n",
              "      <td>finalized</td>\n",
              "      <td>3</td>\n",
              "      <td>10/27/15 1:15</td>\n",
              "      <td>female</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4/16/14 13:23</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/564094871...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Watching Neighbours on Sky+ catching up with t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31462</td>\n",
              "      <td>10/26/15 12:40</td>\n",
              "      <td>6.587300e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20045</th>\n",
              "      <td>815757572</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>259</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8/5/15 21:16</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/656793310...</td>\n",
              "      <td>0</td>\n",
              "      <td>C0DEED</td>\n",
              "      <td>@lookupondeath ...Fine, and I'll drink tea too...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>783</td>\n",
              "      <td>10/26/15 13:20</td>\n",
              "      <td>6.587400e+17</td>\n",
              "      <td>Verona ªÁ</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20046</th>\n",
              "      <td>815757681</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>248</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8/15/12 21:17</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/639815429...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Greg Hardy you a good player and all but don't...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13523</td>\n",
              "      <td>10/26/15 12:40</td>\n",
              "      <td>6.587300e+17</td>\n",
              "      <td>Kansas City, MO</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20047</th>\n",
              "      <td>815757830</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>264</td>\n",
              "      <td>NaN</td>\n",
              "      <td>male</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9/3/12 1:17</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/655473271...</td>\n",
              "      <td>0</td>\n",
              "      <td>C0DEED</td>\n",
              "      <td>You can miss people and still never want to se...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26419</td>\n",
              "      <td>10/26/15 13:20</td>\n",
              "      <td>6.587400e+17</td>\n",
              "      <td>Lagos Nigeria</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20048</th>\n",
              "      <td>815757921</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>0.8489</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11/6/12 23:46</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/657716093...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@bitemyapp i had noticed your tendency to pee ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>56073</td>\n",
              "      <td>10/26/15 12:40</td>\n",
              "      <td>6.587300e+17</td>\n",
              "      <td>Texas Hill Country</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20049</th>\n",
              "      <td>815757985</td>\n",
              "      <td>True</td>\n",
              "      <td>golden</td>\n",
              "      <td>249</td>\n",
              "      <td>NaN</td>\n",
              "      <td>female</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4/14/14 17:22</td>\n",
              "      <td>...</td>\n",
              "      <td>https://pbs.twimg.com/profile_images/655134724...</td>\n",
              "      <td>0</td>\n",
              "      <td>C0DEED</td>\n",
              "      <td>I think for my APUSH creative project I'm goin...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2922</td>\n",
              "      <td>10/26/15 13:19</td>\n",
              "      <td>6.587400e+17</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20050 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3bc24e9f-7a0f-4bb3-8cf8-12415475d633')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3bc24e9f-7a0f-4bb3-8cf8-12415475d633 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3bc24e9f-7a0f-4bb3-8cf8-12415475d633');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1cfc0427-5a32-40d3-ba2d-75223b56d913\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1cfc0427-5a32-40d3-ba2d-75223b56d913')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1cfc0427-5a32-40d3-ba2d-75223b56d913 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b87bc385-289f-41e3-b00a-83de52782f81\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b87bc385-289f-41e3-b00a-83de52782f81 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
              "0      815719226    False   finalized                   3    10/26/15 23:24   \n",
              "1      815719227    False   finalized                   3    10/26/15 23:30   \n",
              "2      815719228    False   finalized                   3    10/26/15 23:33   \n",
              "3      815719229    False   finalized                   3    10/26/15 23:10   \n",
              "4      815719230    False   finalized                   3     10/27/15 1:15   \n",
              "...          ...      ...         ...                 ...               ...   \n",
              "20045  815757572     True      golden                 259               NaN   \n",
              "20046  815757681     True      golden                 248               NaN   \n",
              "20047  815757830     True      golden                 264               NaN   \n",
              "20048  815757921     True      golden                 250               NaN   \n",
              "20049  815757985     True      golden                 249               NaN   \n",
              "\n",
              "       gender  gender:confidence profile_yn  profile_yn:confidence  \\\n",
              "0        male             1.0000        yes                    1.0   \n",
              "1        male             1.0000        yes                    1.0   \n",
              "2        male             0.6625        yes                    1.0   \n",
              "3        male             1.0000        yes                    1.0   \n",
              "4      female             1.0000        yes                    1.0   \n",
              "...       ...                ...        ...                    ...   \n",
              "20045  female             1.0000        yes                    1.0   \n",
              "20046    male             1.0000        yes                    1.0   \n",
              "20047    male             1.0000        yes                    1.0   \n",
              "20048  female             0.8489        yes                    1.0   \n",
              "20049  female             1.0000        yes                    1.0   \n",
              "\n",
              "              created  ...                                       profileimage  \\\n",
              "0        12/5/13 1:48  ...  https://pbs.twimg.com/profile_images/414342229...   \n",
              "1       10/1/12 13:51  ...  https://pbs.twimg.com/profile_images/539604221...   \n",
              "2      11/28/14 11:30  ...  https://pbs.twimg.com/profile_images/657330418...   \n",
              "3       6/11/09 22:39  ...  https://pbs.twimg.com/profile_images/259703936...   \n",
              "4       4/16/14 13:23  ...  https://pbs.twimg.com/profile_images/564094871...   \n",
              "...               ...  ...                                                ...   \n",
              "20045    8/5/15 21:16  ...  https://pbs.twimg.com/profile_images/656793310...   \n",
              "20046   8/15/12 21:17  ...  https://pbs.twimg.com/profile_images/639815429...   \n",
              "20047     9/3/12 1:17  ...  https://pbs.twimg.com/profile_images/655473271...   \n",
              "20048   11/6/12 23:46  ...  https://pbs.twimg.com/profile_images/657716093...   \n",
              "20049   4/14/14 17:22  ...  https://pbs.twimg.com/profile_images/655134724...   \n",
              "\n",
              "       retweet_count sidebar_color  \\\n",
              "0                  0        FFFFFF   \n",
              "1                  0        C0DEED   \n",
              "2                  1        C0DEED   \n",
              "3                  0        C0DEED   \n",
              "4                  0             0   \n",
              "...              ...           ...   \n",
              "20045              0        C0DEED   \n",
              "20046              0             0   \n",
              "20047              0        C0DEED   \n",
              "20048              0             0   \n",
              "20049              0        C0DEED   \n",
              "\n",
              "                                                    text tweet_coord  \\\n",
              "0      Robbie E Responds To Critics After Win Against...         NaN   \n",
              "1      ÛÏIt felt like they were my friends and I was...         NaN   \n",
              "2      i absolutely adore when louis starts the songs...         NaN   \n",
              "3      Hi @JordanSpieth - Looking at the url - do you...         NaN   \n",
              "4      Watching Neighbours on Sky+ catching up with t...         NaN   \n",
              "...                                                  ...         ...   \n",
              "20045  @lookupondeath ...Fine, and I'll drink tea too...         NaN   \n",
              "20046  Greg Hardy you a good player and all but don't...         NaN   \n",
              "20047  You can miss people and still never want to se...         NaN   \n",
              "20048  @bitemyapp i had noticed your tendency to pee ...         NaN   \n",
              "20049  I think for my APUSH creative project I'm goin...         NaN   \n",
              "\n",
              "      tweet_count   tweet_created      tweet_id      tweet_location  \\\n",
              "0          110964  10/26/15 12:40  6.587300e+17     main; @Kan1shk3   \n",
              "1            7471  10/26/15 12:40  6.587300e+17                 NaN   \n",
              "2            5617  10/26/15 12:40  6.587300e+17              clcncl   \n",
              "3            1693  10/26/15 12:40  6.587300e+17       Palo Alto, CA   \n",
              "4           31462  10/26/15 12:40  6.587300e+17                 NaN   \n",
              "...           ...             ...           ...                 ...   \n",
              "20045         783  10/26/15 13:20  6.587400e+17          Verona ªÁ   \n",
              "20046       13523  10/26/15 12:40  6.587300e+17     Kansas City, MO   \n",
              "20047       26419  10/26/15 13:20  6.587400e+17      Lagos Nigeria    \n",
              "20048       56073  10/26/15 12:40  6.587300e+17  Texas Hill Country   \n",
              "20049        2922  10/26/15 13:19  6.587400e+17                 NaN   \n",
              "\n",
              "                    user_timezone  \n",
              "0                         Chennai  \n",
              "1      Eastern Time (US & Canada)  \n",
              "2                        Belgrade  \n",
              "3      Pacific Time (US & Canada)  \n",
              "4                             NaN  \n",
              "...                           ...  \n",
              "20045                         NaN  \n",
              "20046                         NaN  \n",
              "20047                         NaN  \n",
              "20048                         NaN  \n",
              "20049                         NaN  \n",
              "\n",
              "[20050 rows x 26 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beKzTLe7UeR4",
        "outputId": "c9df81a8-c9b4-462a-d851-3fe1f0b810ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10023, 2),\n",
              "             name  gender\n",
              " 0        sheezy0    male\n",
              " 1    DavdBurnett    male\n",
              " 3    douggarland    male\n",
              " 4   WilfordGemma  female\n",
              " 5  monroevicious  female)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter out entries with low confidence in gender identification\n",
        "filtered_data = data[(data['gender:confidence'] > 0.9) & (data['gender'].isin(['male', 'female']))]\n",
        "\n",
        "# Select only the 'name' and 'gender' columns for our task\n",
        "clean_data = filtered_data[['name', 'gender']]\n",
        "\n",
        "# Display the shape of the cleaned data and first few entries\n",
        "clean_data.shape, clean_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwxWnlLbcs03"
      },
      "source": [
        "VOWELS FEATURES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwZn-W6AUq_8",
        "outputId": "a7bdb868-5241-434e-9377-6d1ba653f037"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5775561097256858"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vovel feature\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to extract features\n",
        "def extract_features(name):\n",
        "    name = name.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    features = {\n",
        "        'length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in vowels),\n",
        "        'ends_with_vowel': 1 if name[-1] in vowels else 0,\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Encode the gender labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCaV-0REjiZZ"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4z1LVTJdPBz",
        "outputId": "66d1496a-9168-497b-dc1a-1ed5b4c5be88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5795511221945138"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to extract features\n",
        "def extract_features(name):\n",
        "    name = name.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    features = {\n",
        "        'length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in vowels),\n",
        "        'ends_with_vowel': 1 if name[-1] in vowels else 0,\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Encode the gender labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K_k9cG0j-n3"
      },
      "source": [
        "LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp_aciQKe-ph",
        "outputId": "85259b0a-f65c-4e40-f501-e464d184c9d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5850374064837905"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to extract features\n",
        "def extract_features(name):\n",
        "    name = name.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    features = {\n",
        "        'length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in vowels),\n",
        "        'ends_with_vowel': 1 if name[-1] in vowels else 0,\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Encode the gender labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression classifier\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etPofAKSki2G"
      },
      "source": [
        "**SUPPORT VECTOR CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzgDlYkueOFw",
        "outputId": "32b702ad-b6f2-48e3-875a-226986c180a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5845386533665835"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to extract features\n",
        "def extract_features(name):\n",
        "    name = name.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    features = {\n",
        "        'length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in vowels),\n",
        "        'ends_with_vowel': 1 if name[-1] in vowels else 0,\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Encode the gender labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVC classifier\n",
        "svc = SVC()\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred = svc.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjNwb2wtlD7z"
      },
      "source": [
        "**GRADIENT BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctAH75tCkutr",
        "outputId": "fd791ed4-619c-49c9-d3a1-065a24230c44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5740648379052369"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to extract features\n",
        "def extract_features(name):\n",
        "    name = name.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    features = {\n",
        "        'length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in vowels),\n",
        "        'ends_with_vowel': 1 if name[-1] in vowels else 0,\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Encode the gender labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Gradient Boosting classifier\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred = gbm.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asL9F0simDLs"
      },
      "source": [
        "**XG BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBcnjHQIkuwy",
        "outputId": "8737d85f-6473-4713-df1c-5200b5f8fd49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5790523690773067"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to extract features\n",
        "def extract_features(name):\n",
        "    name = name.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    features = {\n",
        "        'length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in vowels),\n",
        "        'ends_with_vowel': 1 if name[-1] in vowels else 0,\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Encode the gender labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an XGBoost classifier\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred = xgb.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xec6upy4mjWO"
      },
      "source": [
        "**Light Gradient Boosting Machine (LGBM)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eF1EEJ1mGAc",
        "outputId": "33dec0f5-ed4e-4152-c4fc-393326a99790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 26\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5785536159600998"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Helper function to extract features\n",
        "def extract_features(name):\n",
        "    name = name.lower()\n",
        "    vowels = \"aeiou\"\n",
        "    features = {\n",
        "        'length': len(name),\n",
        "        'vowel_count': sum(1 for char in name if char in vowels),\n",
        "        'ends_with_vowel': 1 if name[-1] in vowels else 0,\n",
        "    }\n",
        "    return features\n",
        "# Apply feature extraction to each name\n",
        "features = clean_data['name'].apply(extract_features)\n",
        "feature_df = pd.DataFrame(list(features))\n",
        "\n",
        "# Encode the gender labels\n",
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a LightGBM classifier\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set and evaluate\n",
        "y_pred = lgbm.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "accuracy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KEiQbdoUmGEE"
      },
      "outputs": [],
      "source": [
        "#################################################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A73SrOG0mGmO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE3yZFQLnD8p"
      },
      "source": [
        "**n-grams**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jvPYQz4dVa-y"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BdEvvLZvz2T"
      },
      "source": [
        "n gram for (1,2)\n",
        "\n",
        "**LGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb2QvLt1VcDh",
        "outputId": "22d9c4ea-bb64-4cf1-f1c3-fbf37e12e373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy for GBM: 0.5785536159600998\n",
            "Precision for GBM: 0.6076352067868505\n",
            "Recall for GBM: 0.6373748609566184\n",
            "F1 Score for GBM: 0.6221498371335505\n"
          ]
        }
      ],
      "source": [
        "# Initialize a more limited CountVectorizer to extract n-grams (using unigrams and bigrams only)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# No need to convert to dense, use the sparse representation directly\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "from scipy.sparse import hstack\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Train a new Random Forest classifier on the sparse features\n",
        "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# clf.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on the test set with the new model\n",
        "# y_pred = clf.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# accuracy\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Initialize the Gradient Boosting Classifier\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the GBM on the training data\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_gbm = gbm.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_gbm, recall_gbm, f1_score_gbm, _ = precision_recall_fscore_support(y_test, y_pred_gbm, average='binary')\n",
        "\n",
        "# Output the performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"accuracy for GBM:\", accuracy)\n",
        "print(\"Precision for GBM:\", precision_gbm)\n",
        "print(\"Recall for GBM:\", recall_gbm)\n",
        "print(\"F1 Score for GBM:\", f1_score_gbm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1cRSuMdqLz8"
      },
      "source": [
        "**LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLXxu6FcrMFf",
        "outputId": "0121b544-9837-4727-ffd9-48ac37ab32c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Logistic Regression: 0.6663341645885287\n",
            "Precision for Logistic Regression: 0.625\n",
            "Recall for Logistic Regression: 0.639599555061179\n",
            "F1 Score for Logistic Regression: 0.6322155030236393\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "# Initialize a more limited CountVectorizer to extract n-grams (using unigrams and bigrams only)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# No need to convert to dense, use the sparse representation directly\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "from scipy.sparse import hstack\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the logistic regression model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using logistic regression\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_logreg, recall_logreg, f1_score_logreg, _ = precision_recall_fscore_support(y_test, y_pred_logreg, average='binary')\n",
        "\n",
        "# Output the performance metrics for logistic regression\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(\"Accuracy for Logistic Regression:\", accuracy_logreg)\n",
        "print(\"Precision for Logistic Regression:\", precision_logreg)\n",
        "print(\"Recall for Logistic Regression:\", recall_logreg)\n",
        "print(\"F1 Score for Logistic Regression:\", f1_score_logreg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TbTgtmrxFxv"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_eXKbWtxE9r",
        "outputId": "b871b858-b520-4bc7-fc0a-2ff114587347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Decision Tree: 0.6144638403990025\n",
            "Precision for Decision Tree: 0.5668789808917197\n",
            "Recall for Decision Tree: 0.5939933259176863\n",
            "F1 Score for Decision Tree: 0.5801195002715915\n"
          ]
        }
      ],
      "source": [
        "# Initialize a more limited CountVectorizer to extract n-grams (using unigrams and bigrams only)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# No need to convert to dense, use the sparse representation directly\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "from scipy.sparse import hstack\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the Decision Tree\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "\n",
        "# Output the performance metrics for the Decision Tree\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"Accuracy for Decision Tree:\", accuracy_dt)\n",
        "print(\"Precision for Decision Tree:\", precision_dt)\n",
        "print(\"Recall for Decision Tree:\", recall_dt)\n",
        "print(\"F1 Score for Decision Tree:\", f1_score_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxOigwdVyCHS"
      },
      "source": [
        "**SUPPORT VECTOR CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skkGwXDQyIJO",
        "outputId": "c5287956-b70b-45df-e17b-296e62eeba74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVC: 0.6653366583541147\n",
            "Precision for SVC: 0.6185031185031185\n",
            "Recall for SVC: 0.6618464961067854\n",
            "F1 Score for SVC: 0.6394411606663085\n"
          ]
        }
      ],
      "source": [
        "# Initialize a more limited CountVectorizer to extract n-grams (using unigrams and bigrams only)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# No need to convert to dense, use the sparse representation directly\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "from scipy.sparse import hstack\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the SVC classifier\n",
        "svc = SVC(random_state=42)\n",
        "\n",
        "# Train the SVC on the training data\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the SVC\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "\n",
        "# Output the performance metrics for the SVC\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "print(\"Accuracy for SVC:\", accuracy_svc)\n",
        "print(\"Precision for SVC:\", precision_svc)\n",
        "print(\"Recall for SVC:\", recall_svc)\n",
        "print(\"F1 Score for SVC:\", f1_score_svc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RABSRrQuysef"
      },
      "source": [
        "**RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzgddBrlywsT",
        "outputId": "853ff959-8c49-47e8-8b6a-e1da68222f41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Random Forest: 0.6812967581047381\n",
            "Precision for Random Forest: 0.65625\n",
            "Recall for Random Forest: 0.60734149054505\n",
            "F1 Score for Random Forest: 0.6308492201039861\n"
          ]
        }
      ],
      "source": [
        "# Initialize a more limited CountVectorizer to extract n-grams (using unigrams and bigrams only)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# No need to convert to dense, use the sparse representation directly\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "from scipy.sparse import hstack\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the Random Forest\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "\n",
        "# Output the performance metrics for the Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy for Random Forest:\", accuracy_rf)\n",
        "print(\"Precision for Random Forest:\", precision_rf)\n",
        "print(\"Recall for Random Forest:\", recall_rf)\n",
        "print(\"F1 Score for Random Forest:\", f1_score_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTGHP-M9zQdp"
      },
      "source": [
        "**XG BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B5KBfO7zWoL",
        "outputId": "f24e7188-f651-46b2-fa01-65f04e3fbcdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for XGBoost: 0.6743142144638404\n",
            "Precision for XGBoost: 0.6278586278586279\n",
            "Recall for XGBoost: 0.6718576195773082\n",
            "F1 Score for XGBoost: 0.6491133799032779\n"
          ]
        }
      ],
      "source": [
        "# Initialize a more limited CountVectorizer to extract n-grams (using unigrams and bigrams only)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# No need to convert to dense, use the sparse representation directly\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "from scipy.sparse import hstack\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the XGBoost on the training data\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using XGBoost\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "# Output the performance metrics for XGBoost\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Accuracy for XGBoost:\", accuracy_xgb)\n",
        "print(\"Precision for XGBoost:\", precision_xgb)\n",
        "print(\"Recall for XGBoost:\", recall_xgb)\n",
        "print(\"F1 Score for XGBoost:\", f1_score_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrlrXAEt7Wy5"
      },
      "source": [
        "ENSEMBLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoCFWEG3Vg1A",
        "outputId": "d1071820-10c6-46b7-d598-588a41dee84b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.6453744493392071\n",
            "Recall: 0.6518353726362626\n",
            "F1 Score: 0.6485888212506918\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Initialize the classifiers\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "svm = SVC(probability=True, random_state=42)  # Ensure probability is enabled for soft voting\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Create the voting classifier, combining the models\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "    ('lr', log_reg),\n",
        "    ('svm', svm),\n",
        "    ('gbm', gbm),\n",
        "    ('rf', clf)\n",
        "], voting='soft')\n",
        "\n",
        "# Train the ensemble model\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = ensemble.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "# Output the performance metrics\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9zLEq4jN3bbg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fB4zm0P2cFF"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnoI4ttD2dLI"
      },
      "source": [
        "n gram for (1,3)\n",
        "\n",
        "**LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk1d8dXPzXcu",
        "outputId": "933fea90-2095-425c-c2fa-09369bbb79d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Logistic Regression: 0.713216957605985\n",
            "Precision for Logistic Regression: 0.6730769230769231\n",
            "Recall for Logistic Regression: 0.7007786429365962\n",
            "F1 Score for Logistic Regression: 0.6866485013623979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the logistic regression model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using logistic regression\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_logreg, recall_logreg, f1_score_logreg, _ = precision_recall_fscore_support(y_test, y_pred_logreg, average='binary')\n",
        "\n",
        "# Output the performance metrics for logistic regression\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(\"Accuracy for Logistic Regression:\", accuracy_logreg)\n",
        "print(\"Precision for Logistic Regression:\", precision_logreg)\n",
        "print(\"Recall for Logistic Regression:\", recall_logreg)\n",
        "print(\"F1 Score for Logistic Regression:\", f1_score_logreg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aVxqkV63RqQ"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLMS2y4i3Q-F",
        "outputId": "3905f1f6-4506-4934-ea65-38d221f6d551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Decision Tree: 0.6069825436408978\n",
            "Precision for Decision Tree: 0.5586061246040127\n",
            "Recall for Decision Tree: 0.5884315906562848\n",
            "F1 Score for Decision Tree: 0.5731310942578549\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the Decision Tree\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "\n",
        "# Output the performance metrics for the Decision Tree\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"Accuracy for Decision Tree:\", accuracy_dt)\n",
        "print(\"Precision for Decision Tree:\", precision_dt)\n",
        "print(\"Recall for Decision Tree:\", recall_dt)\n",
        "print(\"F1 Score for Decision Tree:\", f1_score_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMz_Tn3931VT"
      },
      "source": [
        "**SUPPORT VECTOR CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JilKK8oj367t",
        "outputId": "5725b161-f7ae-4e9e-c942-51b2f1f0c196"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVC: 0.685286783042394\n",
            "Precision for SVC: 0.6361788617886179\n",
            "Recall for SVC: 0.696329254727475\n",
            "F1 Score for SVC: 0.6648964418481147\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVC classifier\n",
        "svc = SVC(random_state=42)\n",
        "\n",
        "# Train the SVC on the training data\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using SVC\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "\n",
        "# Output the performance metrics for SVC\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "print(\"Accuracy for SVC:\", accuracy_svc)\n",
        "print(\"Precision for SVC:\", precision_svc)\n",
        "print(\"Recall for SVC:\", recall_svc)\n",
        "print(\"F1 Score for SVC:\", f1_score_svc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL3v06Jx5oM_"
      },
      "source": [
        "**RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ94mYc05k5z",
        "outputId": "5a6c579d-7766-454f-b784-5a592bca8cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Random Forest: 0.6947630922693266\n",
            "Precision for Random Forest: 0.6589147286821705\n",
            "Recall for Random Forest: 0.6618464961067854\n",
            "F1 Score for Random Forest: 0.660377358490566\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the Random Forest\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "\n",
        "# Output the performance metrics for the Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy for Random Forest:\", accuracy_rf)\n",
        "print(\"Precision for Random Forest:\", precision_rf)\n",
        "print(\"Recall for Random Forest:\", recall_rf)\n",
        "print(\"F1 Score for Random Forest:\", f1_score_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwDZdphq50eK"
      },
      "source": [
        "**GRADIENT BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZeO6PlI54zh",
        "outputId": "dd1001df-a729-4f01-e475-28d806c8cd5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Gradient Boosting: 0.6618453865336659\n",
            "Precision for Gradient Boosting: 0.6179295624332978\n",
            "Recall for Gradient Boosting: 0.6440489432703004\n",
            "F1 Score for Gradient Boosting: 0.6307189542483661\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Gradient Boosting classifier\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Gradient Boosting on the training data\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using Gradient Boosting\n",
        "y_pred_gbm = gbm.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_gbm, recall_gbm, f1_score_gbm, _ = precision_recall_fscore_support(y_test, y_pred_gbm, average='binary')\n",
        "\n",
        "# Output the performance metrics for Gradient Boosting\n",
        "accuracy_gbm = accuracy_score(y_test, y_pred_gbm)\n",
        "print(\"Accuracy for Gradient Boosting:\", accuracy_gbm)\n",
        "print(\"Precision for Gradient Boosting:\", precision_gbm)\n",
        "print(\"Recall for Gradient Boosting:\", recall_gbm)\n",
        "print(\"F1 Score for Gradient Boosting:\", f1_score_gbm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzj1qdJJ52wx"
      },
      "source": [
        "**XG BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ou1ZR9W55RE",
        "outputId": "e3ec5dac-81ce-4fb3-c5c7-e9bfde9c0917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for XGBoost: 0.6917705735660847\n",
            "Precision for XGBoost: 0.6455958549222798\n",
            "Recall for XGBoost: 0.692992213570634\n",
            "F1 Score for XGBoost: 0.6684549356223176\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the XGBoost on the training data\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using XGBoost\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "# Output the performance metrics for XGBoost\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Accuracy for XGBoost:\", accuracy_xgb)\n",
        "print(\"Precision for XGBoost:\", precision_xgb)\n",
        "print(\"Recall for XGBoost:\", recall_xgb)\n",
        "print(\"F1 Score for XGBoost:\", f1_score_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JC5Gpc98BLr"
      },
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKGVlVh78BXY",
        "outputId": "cbad49d0-90f2-4091-8620-37b646959b5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 26\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 3\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "Accuracy for LGBM: 0.5785536159600998\n",
            "Precision for LGBM: 0.5291576673866091\n",
            "Recall for LGBM: 0.5450500556173526\n",
            "F1 Score for LGBM: 0.536986301369863\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(feature_df, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the LGBM classifier\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "\n",
        "# Train the LGBM classifier on the training data\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using LGBM\n",
        "y_pred_lgbm = lgbm.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_lgbm, recall_lgbm, f1_score_lgbm, _ = precision_recall_fscore_support(y_test, y_pred_lgbm, average='binary')\n",
        "\n",
        "# Output the performance metrics for LGBM\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "print(\"Accuracy for LGBM:\", accuracy_lgbm)\n",
        "print(\"Precision for LGBM:\", precision_lgbm)\n",
        "print(\"Recall for LGBM:\", recall_lgbm)\n",
        "print(\"F1 Score for LGBM:\", f1_score_lgbm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_bi-w-X65JA"
      },
      "source": [
        "ENSEMBLE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KzWNbXd63_k",
        "outputId": "ad8b171e-37ea-42f5-a814-440ae415e223"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Ensemble of all models with n-gram (1,3): 0.7007481296758105\n",
            "Precision for Ensemble of all models with n-gram (1,3): 0.6716417910447762\n",
            "Recall for Ensemble of all models with n-gram (1,3): 0.6507230255839822\n",
            "F1 Score for Ensemble of all models with n-gram (1,3): 0.6610169491525424\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the classifiers\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "svc = SVC(random_state=42)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Create the ensemble of classifiers\n",
        "ensemble = VotingClassifier(estimators=[\n",
        "    ('logreg', logreg),\n",
        "    ('dt', dt),\n",
        "    ('svc', svc),\n",
        "    ('rf', rf),\n",
        "    ('gbm', gbm),\n",
        "    ('xgb', xgb)\n",
        "], voting='hard')\n",
        "\n",
        "# Train the ensemble on the training data\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the ensemble\n",
        "y_pred_ensemble = ensemble.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for the ensemble\n",
        "precision_ensemble, recall_ensemble, f1_score_ensemble, _ = precision_recall_fscore_support(y_test, y_pred_ensemble, average='binary')\n",
        "\n",
        "# Output the performance metrics for the ensemble\n",
        "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
        "print(\"Accuracy for Ensemble of all models with n-gram (1,3):\", accuracy_ensemble)\n",
        "print(\"Precision for Ensemble of all models with n-gram (1,3):\", precision_ensemble)\n",
        "print(\"Recall for Ensemble of all models with n-gram (1,3):\", recall_ensemble)\n",
        "print(\"F1 Score for Ensemble of all models with n-gram (1,3):\", f1_score_ensemble)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNOQ5HcO8Zl9"
      },
      "source": [
        "n gram for (2,3)\n",
        "\n",
        "***LOGISTIC REGRESSION ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yS1d_GV64Qd",
        "outputId": "005b5d3a-6bae-402e-b6ee-39de05cf4315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Logistic Regression with n-gram (2,3): 0.7167082294264339\n",
            "Precision for Logistic Regression with n-gram (2,3): 0.6804798255179935\n",
            "Recall for Logistic Regression with n-gram (2,3): 0.6941045606229144\n",
            "F1 Score for Logistic Regression with n-gram (2,3): 0.6872246696035242\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Split the data with the n-gram features\n",
        "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train Logistic Regression on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using Logistic Regression\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_logreg, recall_logreg, f1_score_logreg, _ = precision_recall_fscore_support(y_test, y_pred_logreg, average='binary')\n",
        "\n",
        "# Output the performance metrics for Logistic Regression\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(\"Accuracy for Logistic Regression with n-gram (2,3):\", accuracy_logreg)\n",
        "print(\"Precision for Logistic Regression with n-gram (2,3):\", precision_logreg)\n",
        "print(\"Recall for Logistic Regression with n-gram (2,3):\", recall_logreg)\n",
        "print(\"F1 Score for Logistic Regression with n-gram (2,3):\", f1_score_logreg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN0ohAWW8jqM"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxfiou5D8mzR",
        "outputId": "48bb4d6b-43e9-4713-b55b-e4623bf02974"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Decision Tree with n-gram (2,3): 0.6413965087281795\n",
            "Precision for Decision Tree with n-gram (2,3): 0.5963597430406852\n",
            "Recall for Decision Tree with n-gram (2,3): 0.6195773081201335\n",
            "F1 Score for Decision Tree with n-gram (2,3): 0.607746863066012\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Split the data with the n-gram features\n",
        "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the Decision Tree\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "\n",
        "# Output the performance metrics for the Decision Tree\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"Accuracy for Decision Tree with n-gram (2,3):\", accuracy_dt)\n",
        "print(\"Precision for Decision Tree with n-gram (2,3):\", precision_dt)\n",
        "print(\"Recall for Decision Tree with n-gram (2,3):\", recall_dt)\n",
        "print(\"F1 Score for Decision Tree with n-gram (2,3):\", f1_score_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwIpuuUt87ay"
      },
      "source": [
        "**SUPPORT VECTOR CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzMEIo8B87h1",
        "outputId": "aa7ee1e0-c961-4cde-d83c-4c390360a3c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVC with n-gram (2,3): 0.7256857855361596\n",
            "Precision for SVC with n-gram (2,3): 0.6838777660695469\n",
            "Recall for SVC with n-gram (2,3): 0.7219132369299222\n",
            "F1 Score for SVC with n-gram (2,3): 0.7023809523809524\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Split the data with the n-gram features\n",
        "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVC classifier\n",
        "svc = SVC(random_state=42)\n",
        "\n",
        "# Train the SVC on the training data\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using SVC\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "\n",
        "# Output the performance metrics for SVC\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "print(\"Accuracy for SVC with n-gram (2,3):\", accuracy_svc)\n",
        "print(\"Precision for SVC with n-gram (2,3):\", precision_svc)\n",
        "print(\"Recall for SVC with n-gram (2,3):\", recall_svc)\n",
        "print(\"F1 Score for SVC with n-gram (2,3):\", f1_score_svc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv_odJPi9aMV"
      },
      "source": [
        "**RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98EYTQPM9aYk",
        "outputId": "a5fa3605-b52f-4e36-dfe3-c6d0f9233c76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Random Forest with n-gram (2,3): 0.7077306733167082\n",
            "Precision for Random Forest with n-gram (2,3): 0.6729281767955801\n",
            "Recall for Random Forest with n-gram (2,3): 0.6774193548387096\n",
            "F1 Score for Random Forest with n-gram (2,3): 0.6751662971175167\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Split the data with the n-gram features\n",
        "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using Random Forest\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "\n",
        "# Output the performance metrics for Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy for Random Forest with n-gram (2,3):\", accuracy_rf)\n",
        "print(\"Precision for Random Forest with n-gram (2,3):\", precision_rf)\n",
        "print(\"Recall for Random Forest with n-gram (2,3):\", recall_rf)\n",
        "print(\"F1 Score for Random Forest with n-gram (2,3):\", f1_score_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOUoHiI698M5"
      },
      "source": [
        "**GRADIENT BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCTA_B9m98Y5",
        "outputId": "e116015f-2e98-4ba0-91e5-c803d77a5588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Gradient Boosting with n-gram (2,3): 0.6688279301745635\n",
            "Precision for Gradient Boosting with n-gram (2,3): 0.6176176176176176\n",
            "Recall for Gradient Boosting with n-gram (2,3): 0.6863181312569522\n",
            "F1 Score for Gradient Boosting with n-gram (2,3): 0.6501580611169653\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Split the data with the n-gram features\n",
        "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Gradient Boosting classifier\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Gradient Boosting on the training data\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using Gradient Boosting\n",
        "y_pred_gbm = gbm.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_gbm, recall_gbm, f1_score_gbm, _ = precision_recall_fscore_support(y_test, y_pred_gbm, average='binary')\n",
        "\n",
        "# Output the performance metrics for Gradient Boosting\n",
        "accuracy_gbm = accuracy_score(y_test, y_pred_gbm)\n",
        "print(\"Accuracy for Gradient Boosting with n-gram (2,3):\", accuracy_gbm)\n",
        "print(\"Precision for Gradient Boosting with n-gram (2,3):\", precision_gbm)\n",
        "print(\"Recall for Gradient Boosting with n-gram (2,3):\", recall_gbm)\n",
        "print(\"F1 Score for Gradient Boosting with n-gram (2,3):\", f1_score_gbm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiQKFTw--Ako"
      },
      "source": [
        "**XG BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ned7J_ak-Ar8",
        "outputId": "bba81c28-617b-448d-e32a-61ac75c4c66f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for XGBoost with n-gram (2,3): 0.6917705735660847\n",
            "Precision for XGBoost with n-gram (2,3): 0.6414904330312186\n",
            "Recall for XGBoost with n-gram (2,3): 0.7085650723025584\n",
            "F1 Score for XGBoost with n-gram (2,3): 0.6733615221987316\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Split the data with the n-gram features\n",
        "X_train, X_test, y_train, y_test = train_test_split(ngram_features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the XGBoost on the training data\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using XGBoost\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "# Output the performance metrics for XGBoost\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Accuracy for XGBoost with n-gram (2,3):\", accuracy_xgb)\n",
        "print(\"Precision for XGBoost with n-gram (2,3):\", precision_xgb)\n",
        "print(\"Recall for XGBoost with n-gram (2,3):\", recall_xgb)\n",
        "print(\"F1 Score for XGBoost with n-gram (2,3):\", f1_score_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPEivolh-CxO"
      },
      "source": [
        "**LGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKzpwPoW-C27",
        "outputId": "87c9ed9b-9405-4cf2-c7e5-506b363ae76f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051466 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3203\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 1345\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "Accuracy for LGBM with n-gram (2,3): 0.6972568578553616\n",
            "Precision for LGBM with n-gram (2,3): 0.6508264462809917\n",
            "Recall for LGBM with n-gram (2,3): 0.7007786429365962\n",
            "F1 Score for LGBM with n-gram (2,3): 0.674879485806106\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 3)\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the n-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the sparse matrix to float32\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Initialize the LGBM classifier\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "\n",
        "# Train the LGBM classifier on the training data\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using LGBM\n",
        "y_pred_lgbm = lgbm.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_lgbm, recall_lgbm, f1_score_lgbm, _ = precision_recall_fscore_support(y_test, y_pred_lgbm, average='binary')\n",
        "\n",
        "# Output the performance metrics for LGBM\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "print(\"Accuracy for LGBM with n-gram (2,3):\", accuracy_lgbm)\n",
        "print(\"Precision for LGBM with n-gram (2,3):\", precision_lgbm)\n",
        "print(\"Recall for LGBM with n-gram (2,3):\", recall_lgbm)\n",
        "print(\"F1 Score for LGBM with n-gram (2,3):\", f1_score_lgbm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "udwd52P85k8m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8WtBAnOA4SL"
      },
      "source": [
        "n-gram (1,1)\n",
        "\n",
        "**LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRhbssvRCTok",
        "outputId": "77cbf238-55d1-48d3-f670-47d190870099"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Logistic Regression with unigrams (1,1): 0.6339152119700748\n",
            "Precision for Logistic Regression with unigrams (1,1): 0.5947187141216992\n",
            "Recall for Logistic Regression with unigrams (1,1): 0.5761957730812013\n",
            "F1 Score for Logistic Regression with unigrams (1,1): 0.5853107344632767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 1) for unigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# No need to convert to dense, use the sparse representation directly\n",
        "# Combine the original features with the unigram features using a horizontal stack since they are sparse\n",
        "from scipy.sparse import hstack\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the logistic regression model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using logistic regression\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_logreg, recall_logreg, f1_score_logreg, _ = precision_recall_fscore_support(y_test, y_pred_logreg, average='binary')\n",
        "\n",
        "# Output the performance metrics for logistic regression\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(\"Accuracy for Logistic Regression with unigrams (1,1):\", accuracy_logreg)\n",
        "print(\"Precision for Logistic Regression with unigrams (1,1):\", precision_logreg)\n",
        "print(\"Recall for Logistic Regression with unigrams (1,1):\", recall_logreg)\n",
        "print(\"F1 Score for Logistic Regression with unigrams (1,1):\", f1_score_logreg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOWsd_k_DPHJ"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxOwAzQMDPTi",
        "outputId": "f70551fa-153f-401d-ceb8-61dd76a2f5d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Decision Tree with unigrams (1,1): 0.571072319201995\n",
            "Precision for Decision Tree with unigrams (1,1): 0.5204616998950682\n",
            "Recall for Decision Tree with unigrams (1,1): 0.5517241379310345\n",
            "F1 Score for Decision Tree with unigrams (1,1): 0.5356371490280777\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 1) for unigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the unigram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree on the training data\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the Decision Tree\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "\n",
        "# Output the performance metrics for the Decision Tree\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"Accuracy for Decision Tree with unigrams (1,1):\", accuracy_dt)\n",
        "print(\"Precision for Decision Tree with unigrams (1,1):\", precision_dt)\n",
        "print(\"Recall for Decision Tree with unigrams (1,1):\", recall_dt)\n",
        "print(\"F1 Score for Decision Tree with unigrams (1,1):\", f1_score_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IyjteXbE_IL"
      },
      "source": [
        "**SUPPORT VECTOR CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbKL7dFlE_UG",
        "outputId": "61fc365a-046c-4fe5-e56b-8a88f5b5f1c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVC with unigrams (1,1): 0.6418952618453866\n",
            "Precision for SVC with unigrams (1,1): 0.6027241770715096\n",
            "Recall for SVC with unigrams (1,1): 0.5906562847608454\n",
            "F1 Score for SVC with unigrams (1,1): 0.5966292134831461\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 1) for unigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the unigram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVC classifier\n",
        "svc = SVC()\n",
        "\n",
        "# Train the SVC on the training data\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the SVC\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "\n",
        "# Output the performance metrics for the SVC\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "print(\"Accuracy for SVC with unigrams (1,1):\", accuracy_svc)\n",
        "print(\"Precision for SVC with unigrams (1,1):\", precision_svc)\n",
        "print(\"Recall for SVC with unigrams (1,1):\", recall_svc)\n",
        "print(\"F1 Score for SVC with unigrams (1,1):\", f1_score_svc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui7AYfzbFlOY"
      },
      "source": [
        "**RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbREgAmjFlf4",
        "outputId": "d212987d-3f20-4129-d27c-b5ef9f463bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Random Forest with unigrams (1,1): 0.6538653366583541\n",
            "Precision for Random Forest with unigrams (1,1): 0.6201641266119577\n",
            "Recall for Random Forest with unigrams (1,1): 0.5884315906562848\n",
            "F1 Score for Random Forest with unigrams (1,1): 0.6038812785388129\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 1) for unigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the unigram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the Random Forest\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "\n",
        "# Output the performance metrics for the Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy for Random Forest with unigrams (1,1):\", accuracy_rf)\n",
        "print(\"Precision for Random Forest with unigrams (1,1):\", precision_rf)\n",
        "print(\"Recall for Random Forest with unigrams (1,1):\", recall_rf)\n",
        "print(\"F1 Score for Random Forest with unigrams (1,1):\", f1_score_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHb_W_1MF10t"
      },
      "source": [
        "**GRADIENT BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekrR3TiQF18N",
        "outputId": "60a981ef-43b7-4b22-b546-499c7b463061"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Gradient Boosting with unigrams (1,1): 0.6314214463840399\n",
            "Precision for Gradient Boosting with unigrams (1,1): 0.5877192982456141\n",
            "Recall for Gradient Boosting with unigrams (1,1): 0.5962180200222469\n",
            "F1 Score for Gradient Boosting with unigrams (1,1): 0.5919381557150746\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 1) for unigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the unigram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Gradient Boosting Classifier\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the GBM on the training data\n",
        "gbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_gbm = gbm.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_gbm, recall_gbm, f1_score_gbm, _ = precision_recall_fscore_support(y_test, y_pred_gbm, average='binary')\n",
        "\n",
        "# Output the performance metrics\n",
        "accuracy_gbm = accuracy_score(y_test, y_pred_gbm)\n",
        "print(\"Accuracy for Gradient Boosting with unigrams (1,1):\", accuracy_gbm)\n",
        "print(\"Precision for Gradient Boosting with unigrams (1,1):\", precision_gbm)\n",
        "print(\"Recall for Gradient Boosting with unigrams (1,1):\", recall_gbm)\n",
        "print(\"F1 Score for Gradient Boosting with unigrams (1,1):\", f1_score_gbm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4-tT2lHF_Pm"
      },
      "source": [
        "XG BOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF8H9q88F_Y5",
        "outputId": "f33f0ffd-2e43-4a72-9f4f-1476584389c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for XGBoost with unigrams (1,1): 0.6413965087281795\n",
            "Precision for XGBoost with unigrams (1,1): 0.6\n",
            "Recall for XGBoost with unigrams (1,1): 0.6006674082313682\n",
            "F1 Score for XGBoost with unigrams (1,1): 0.6003335186214563\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 1) for unigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the unigram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the XGBoost on the training data\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using XGBoost\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "# Output the performance metrics for XGBoost\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Accuracy for XGBoost with unigrams (1,1):\", accuracy_xgb)\n",
        "print(\"Precision for XGBoost with unigrams (1,1):\", precision_xgb)\n",
        "print(\"Recall for XGBoost with unigrams (1,1):\", recall_xgb)\n",
        "print(\"F1 Score for XGBoost with unigrams (1,1):\", f1_score_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLvEpnpgHcNH"
      },
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZn2KXriE44P",
        "outputId": "14736eef-a756-4bee-b1e7-686f31e249f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 221\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 40\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "Accuracy for LGBM with unigrams (1,1): 0.6379052369077307\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (1, 1) for unigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the unigram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert input features to np.float32\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "# Initialize the LightGBM classifier\n",
        "lgbm = LGBMClassifier(random_state=42)\n",
        "\n",
        "# Train the LGBM classifier on the training data\n",
        "lgbm.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using the trained LGBM classifier\n",
        "y_pred_lgbm = lgbm.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "print(\"Accuracy for LGBM with unigrams (1,1):\", accuracy_lgbm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gsc62MoUH5Yz"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5qn4PVUZDOLO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tTGZp-ECG60"
      },
      "source": [
        "n-gram (2,2)\n",
        "\n",
        "LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e184CikBCHBl",
        "outputId": "0eb2cbaa-9616-469e-cc93-ced6354f8ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Logistic Regression with bi-grams (2,2): 0.6618453865336659\n",
            "Precision for Logistic Regression with bi-grams (2,2): 0.6223698781838317\n",
            "Recall for Logistic Regression with bi-grams (2,2): 0.625139043381535\n",
            "F1 Score for Logistic Regression with bi-grams (2,2): 0.6237513873473919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the logistic regression model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using logistic regression\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_logreg, recall_logreg, f1_score_logreg, _ = precision_recall_fscore_support(y_test, y_pred_logreg, average='binary')\n",
        "\n",
        "# Output the performance metrics for logistic regression with bi-grams\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(\"Accuracy for Logistic Regression with bi-grams (2,2):\", accuracy_logreg)\n",
        "print(\"Precision for Logistic Regression with bi-grams (2,2):\", precision_logreg)\n",
        "print(\"Recall for Logistic Regression with bi-grams (2,2):\", recall_logreg)\n",
        "print(\"F1 Score for Logistic Regression with bi-grams (2,2):\", f1_score_logreg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukkHcPt8KCUV"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0IvCA6iKCgj",
        "outputId": "409df9a1-afbb-483c-b13a-306df2a75297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Decision Tree: 0.6339152119700748\n",
            "Precision for Decision Tree: 0.5925925925925926\n",
            "Recall for Decision Tree: 0.5873192436040044\n",
            "F1 Score for Decision Tree: 0.5899441340782123\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the Decision Tree model on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using Decision Tree\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for Decision Tree\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "\n",
        "# Output the performance metrics for Decision Tree\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "print(\"Accuracy for Decision Tree:\", accuracy_dt)\n",
        "print(\"Precision for Decision Tree:\", precision_dt)\n",
        "print(\"Recall for Decision Tree:\", recall_dt)\n",
        "print(\"F1 Score for Decision Tree:\", f1_score_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWc0sZrcKCoG"
      },
      "source": [
        "SUPPORT VECTOR CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq9g-RptKCuU",
        "outputId": "c2783a24-96db-459e-b9e9-9071e0d31822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for SVC: 0.6683291770573566\n",
            "Precision for SVC: 0.6163021868787276\n",
            "Recall for SVC: 0.6896551724137931\n",
            "F1 Score for SVC: 0.6509186351706037\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Support Vector Classifier\n",
        "svc_classifier = SVC(random_state=42)\n",
        "\n",
        "# Train the SVC model on the training data\n",
        "svc_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using SVC\n",
        "y_pred_svc = svc_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for SVC\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "\n",
        "# Output the performance metrics for SVC\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "print(\"Accuracy for SVC:\", accuracy_svc)\n",
        "print(\"Precision for SVC:\", precision_svc)\n",
        "print(\"Recall for SVC:\", recall_svc)\n",
        "print(\"F1 Score for SVC:\", f1_score_svc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8fSmA1aKC05"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYZ8DHL1KC7J",
        "outputId": "56d0bce8-f636-4f8c-a989-1157fd5cbc9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Random Forest: 0.6947630922693266\n",
            "Precision for Random Forest: 0.6694214876033058\n",
            "Recall for Random Forest: 0.6307007786429366\n",
            "F1 Score for Random Forest: 0.6494845360824743\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the Random Forest model on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using Random Forest\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for Random Forest\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "\n",
        "# Output the performance metrics for Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Accuracy for Random Forest:\", accuracy_rf)\n",
        "print(\"Precision for Random Forest:\", precision_rf)\n",
        "print(\"Recall for Random Forest:\", recall_rf)\n",
        "print(\"F1 Score for Random Forest:\", f1_score_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k86fbLGRKDB6"
      },
      "source": [
        "GRADIENT BOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUfyCOy3KDI4",
        "outputId": "432db980-e8f4-4ea0-ae36-ba9934dc4144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Gradient Boosting: 0.6548628428927681\n",
            "Precision for Gradient Boosting: 0.6025768087215064\n",
            "Recall for Gradient Boosting: 0.6763070077864294\n",
            "F1 Score for Gradient Boosting: 0.6373165618448636\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Gradient Boosting classifier\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Train the Gradient Boosting model on the training data\n",
        "gb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using Gradient Boosting\n",
        "y_pred_gb = gb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for Gradient Boosting\n",
        "precision_gb, recall_gb, f1_score_gb, _ = precision_recall_fscore_support(y_test, y_pred_gb, average='binary')\n",
        "\n",
        "# Output the performance metrics for Gradient Boosting\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "print(\"Accuracy for Gradient Boosting:\", accuracy_gb)\n",
        "print(\"Precision for Gradient Boosting:\", precision_gb)\n",
        "print(\"Recall for Gradient Boosting:\", recall_gb)\n",
        "print(\"F1 Score for Gradient Boosting:\", f1_score_gb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhiiWHoEKDPK"
      },
      "source": [
        "XG BOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tetHkB_6KDVZ",
        "outputId": "db4c57aa-6ba7-4037-c04f-e56bb7acbcae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for XGBoost: 0.6837905236907731\n",
            "Precision for XGBoost: 0.6381647549530761\n",
            "Recall for XGBoost: 0.6807563959955506\n",
            "F1 Score for XGBoost: 0.658772874058127\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the XGBoost model on the training data\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using XGBoost\n",
        "y_pred_xgb = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for XGBoost\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "# Output the performance metrics for XGBoost\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(\"Accuracy for XGBoost:\", accuracy_xgb)\n",
        "print(\"Precision for XGBoost:\", precision_xgb)\n",
        "print(\"Recall for XGBoost:\", recall_xgb)\n",
        "print(\"F1 Score for XGBoost:\", f1_score_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCeDGesNKDba"
      },
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boU4Lb3FKDhY",
        "outputId": "535972b7-78cd-4532-ee5a-c57763ce2fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019860 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1369\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 520\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "Accuracy for LightGBM: 0.686284289276808\n",
            "Precision for LightGBM: 0.6439232409381663\n",
            "Recall for LightGBM: 0.6718576195773082\n",
            "F1 Score for LightGBM: 0.6575939031028851\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bi-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bi-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert input features to np.float32\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "# Initialize the LightGBM classifier\n",
        "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Train the LightGBM model on the training data\n",
        "lgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using LightGBM\n",
        "y_pred_lgb = lgb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score for LightGBM\n",
        "precision_lgb, recall_lgb, f1_score_lgb, _ = precision_recall_fscore_support(y_test, y_pred_lgb, average='binary')\n",
        "\n",
        "# Output the performance metrics for LightGBM\n",
        "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
        "print(\"Accuracy for LightGBM:\", accuracy_lgb)\n",
        "print(\"Precision for LightGBM:\", precision_lgb)\n",
        "print(\"Recall for LightGBM:\", recall_lgb)\n",
        "print(\"F1 Score for LightGBM:\", f1_score_lgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugI3YKZmkKy4"
      },
      "source": [
        "**ENSEMBLE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZGMeL8KSXKf",
        "outputId": "a14cd0ad-36db-4600-fa2a-49d55caaac6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Model:\n",
            "Accuracy: 0.683291770573566\n",
            "Precision: 0.6524249422632794\n",
            "Recall: 0.628476084538376\n",
            "F1 Score: 0.6402266288951841\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (2, 2) for bigrams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(2, 2))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the bigram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "svc_classifier = SVC(random_state=42)\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "\n",
        "# Create an ensemble model with voting\n",
        "ensemble_model = VotingClassifier(estimators=[\n",
        "    ('logreg', logreg),\n",
        "    ('dt', dt_classifier),\n",
        "    ('svc', svc_classifier),\n",
        "    ('rf', rf_classifier),\n",
        "    ('gb', gb_classifier),\n",
        "    ('xgb', xgb_classifier)\n",
        "], voting='hard')\n",
        "\n",
        "# Train the ensemble model on the training data\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_ensemble = ensemble_model.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_ensemble, recall_ensemble, f1_score_ensemble, _ = precision_recall_fscore_support(y_test, y_pred_ensemble, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_ensemble = accuracy_score(y_test, y_pred_ensemble)\n",
        "\n",
        "# Output the performance metrics for the ensemble model\n",
        "print(\"Ensemble Model:\")\n",
        "print(\"Accuracy:\", accuracy_ensemble)\n",
        "print(\"Precision:\", precision_ensemble)\n",
        "print(\"Recall:\", recall_ensemble)\n",
        "print(\"F1 Score:\", f1_score_ensemble)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "r5KOCohsM2uh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UstHeBi5Mqvj"
      },
      "source": [
        "n-gram (3,3)\n",
        "\n",
        "**LOGISTIC REGRESSION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Br1KvMUMq8E",
        "outputId": "1f920865-08e5-43ed-fbbf-0da27e0899c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for Logistic Regression with tri-grams (3,3): 0.7072319201995012\n",
            "Precision for Logistic Regression with tri-grams (3,3): 0.662839248434238\n",
            "Recall for Logistic Regression with tri-grams (3,3): 0.7063403781979978\n",
            "F1 Score for Logistic Regression with tri-grams (3,3): 0.683898761443188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (3, 3) for tri-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the tri-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "logreg = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the logistic regression model on the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set using logistic regression\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_logreg, recall_logreg, f1_score_logreg, _ = precision_recall_fscore_support(y_test, y_pred_logreg, average='binary')\n",
        "\n",
        "# Output the performance metrics for logistic regression with tri-grams\n",
        "accuracy_logreg = accuracy_score(y_test, y_pred_logreg)\n",
        "print(\"Accuracy for Logistic Regression with tri-grams (3,3):\", accuracy_logreg)\n",
        "print(\"Precision for Logistic Regression with tri-grams (3,3):\", precision_logreg)\n",
        "print(\"Recall for Logistic Regression with tri-grams (3,3):\", recall_logreg)\n",
        "print(\"F1 Score for Logistic Regression with tri-grams (3,3):\", f1_score_logreg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdtgE_OLN0Iv"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1xywcFXN0dl",
        "outputId": "2b6eaa46-ef79-4fdd-e0d3-1d8f02a3b0be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Classifier:\n",
            "Accuracy: 0.6463840399002494\n",
            "Precision: 0.5904761904761905\n",
            "Recall: 0.6896551724137931\n",
            "F1 Score: 0.6362237044638276\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (3, 3) for tri-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the tri-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_dt = dt_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Output the performance metrics for Decision Tree classifier\n",
        "print(\"Decision Tree Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_dt)\n",
        "print(\"Precision:\", precision_dt)\n",
        "print(\"Recall:\", recall_dt)\n",
        "print(\"F1 Score:\", f1_score_dt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTO5_dZtN0q3"
      },
      "source": [
        "SUPPORT VECTOR CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EksoJ0jN0xy",
        "outputId": "96d0d276-d336-42b2-a305-2145470c4a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Classifier:\n",
            "Accuracy: 0.6713216957605985\n",
            "Precision: 0.6239669421487604\n",
            "Recall: 0.6718576195773082\n",
            "F1 Score: 0.6470273165506161\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (3, 3) for tri-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the tri-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize SVC classifier\n",
        "svc_classifier = SVC(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "svc_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svc = svc_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "\n",
        "# Output the performance metrics for SVC classifier\n",
        "print(\"Support Vector Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_svc)\n",
        "print(\"Precision:\", precision_svc)\n",
        "print(\"Recall:\", recall_svc)\n",
        "print(\"F1 Score:\", f1_score_svc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh4eN0WaN04W"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQDAun-xN0-E",
        "outputId": "164d5572-6ed2-4025-c233-e0e94135b647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier:\n",
            "Accuracy: 0.7082294264339152\n",
            "Precision: 0.6605316973415133\n",
            "Recall: 0.7185761957730812\n",
            "F1 Score: 0.6883324453915822\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (3, 3) for tri-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the tri-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# Output the performance metrics for Random Forest classifier\n",
        "print(\"Random Forest Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_rf)\n",
        "print(\"Precision:\", precision_rf)\n",
        "print(\"Recall:\", recall_rf)\n",
        "print(\"F1 Score:\", f1_score_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBXYSjG8N1EV"
      },
      "source": [
        "GRADIENT BOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7DctEdnN1Jj",
        "outputId": "e56ad4bb-1e91-41e2-c8e8-cd6d53ef796f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient Boosting Classifier:\n",
            "Accuracy: 0.654364089775561\n",
            "Precision: 0.6214622641509434\n",
            "Recall: 0.5862068965517241\n",
            "F1 Score: 0.6033199771036062\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (3, 3) for tri-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the tri-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Gradient Boosting classifier\n",
        "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "gb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_gb = gb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_gb, recall_gb, f1_score_gb, _ = precision_recall_fscore_support(y_test, y_pred_gb, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
        "\n",
        "# Output the performance metrics for Gradient Boosting classifier\n",
        "print(\"Gradient Boosting Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_gb)\n",
        "print(\"Precision:\", precision_gb)\n",
        "print(\"Recall:\", recall_gb)\n",
        "print(\"F1 Score:\", f1_score_gb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhHq6MzZN1PQ"
      },
      "source": [
        "XG BOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtJHANR7N1U-",
        "outputId": "1d1c8f39-e891-484c-ee5b-4d616b5929a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Classifier:\n",
            "Accuracy: 0.6887780548628429\n",
            "Precision: 0.6308277830637488\n",
            "Recall: 0.7374860956618465\n",
            "F1 Score: 0.68\n"
          ]
        }
      ],
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (3, 3) for tri-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the tri-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_classifier = XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_xgb = xgb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Output the performance metrics for XGBoost classifier\n",
        "print(\"XGBoost Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_xgb)\n",
        "print(\"Precision:\", precision_xgb)\n",
        "print(\"Recall:\", recall_xgb)\n",
        "print(\"F1 Score:\", f1_score_xgb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiOs_pbdN1c0"
      },
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kj6dmf5N1iQ",
        "outputId": "865e83b3-0056-4644-e2c7-fd64729c0222"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029746 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1860\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 828\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "LightGBM Classifier:\n",
            "Accuracy: 0.6902743142144638\n",
            "Precision: 0.6336538461538461\n",
            "Recall: 0.7330367074527252\n",
            "F1 Score: 0.6797318205260442\n"
          ]
        }
      ],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# Initialize CountVectorizer with n-gram range (3, 3) for tri-grams only\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
        "\n",
        "# Fit and transform the names to n-gram frequency vectors, keeping the output sparse\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Combine the original features with the tri-gram features using a horizontal stack since they are sparse\n",
        "combined_features_sparse = hstack([feature_df, ngram_features])\n",
        "\n",
        "# Split the data with the new combined sparse features\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features_sparse, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert input features to np.float32\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "\n",
        "# Initialize LightGBM classifier\n",
        "lgbm_classifier = LGBMClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "lgbm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lgbm = lgbm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate precision, recall, and F1-score\n",
        "precision_lgbm, recall_lgbm, f1_score_lgbm, _ = precision_recall_fscore_support(y_test, y_pred_lgbm, average='binary')\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "\n",
        "# Output the performance metrics for LightGBM classifier\n",
        "print(\"LightGBM Classifier:\")\n",
        "print(\"Accuracy:\", accuracy_lgbm)\n",
        "print(\"Precision:\", precision_lgbm)\n",
        "print(\"Recall:\", recall_lgbm)\n",
        "print(\"F1 Score:\", f1_score_lgbm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsW7V1DYSPKx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IktjuNvsA5JL"
      },
      "outputs": [],
      "source": [
        "#####################################################################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-g3TbyPTDim"
      },
      "source": [
        "#CULTURAL ORIGIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBD9C9pTWC7T",
        "outputId": "113301e7-4ecb-4aee-a6ec-94ca62830feb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-59-7abc436737df>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['cultural_origin'] = clean_data['name'].apply(infer_cultural_origin)\n",
            "<ipython-input-59-7abc436737df>:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['ends_with_vowel'] = clean_data['name'].apply(ends_with_vowel)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6708229426433915, Precision: 0.6289104638619202, Recall: 0.6484983314794216, F1 Score: 0.6385542168674699\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('gender-classifier.csv', encoding='latin-1')\n",
        "\n",
        "# Filter out entries with low confidence in gender identification\n",
        "filtered_data = data[(data['gender:confidence'] > 0.9) & (data['gender'].isin(['male', 'female']))]\n",
        "\n",
        "# Select only the 'name' and 'gender' columns for our task\n",
        "clean_data = filtered_data[['name', 'gender']]\n",
        "\n",
        "# Display the shape of the cleaned data and first few entries\n",
        "clean_data.shape, clean_data.head()\n",
        "\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 3))\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Create feature DataFrame from n-grams\n",
        "feature_df = pd.DataFrame(ngram_features.todense(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Function to infer cultural origin (needs to be defined or included)\n",
        "def infer_cultural_origin(name):\n",
        "    name = name.lower()\n",
        "    if any(x in name for x in ['x', 'q', 'zh', 'wang', 'li']):\n",
        "        return 'East Asian'\n",
        "    elif any(x in name for x in ['patel', 'kumar', 'singh']):\n",
        "        return 'South Asian'\n",
        "    elif any(x in name for x in ['smith', 'johnson', 'williams']):\n",
        "        return 'Western'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "# Function to check if the name ends with a vowel\n",
        "def ends_with_vowel(name):\n",
        "    return 1 if name[-1].lower() in 'aeiou' else 0\n",
        "\n",
        "# Create additional features based on cultural origin and vowel ending\n",
        "clean_data['cultural_origin'] = clean_data['name'].apply(infer_cultural_origin)\n",
        "clean_data['ends_with_vowel'] = clean_data['name'].apply(ends_with_vowel)\n",
        "cultural_dummies = pd.get_dummies(clean_data['cultural_origin'], prefix='origin')\n",
        "\n",
        "# Combine all features\n",
        "feature_df = feature_df.join(cultural_dummies)\n",
        "feature_df['ends_with_vowel'] = clean_data['ends_with_vowel'].values\n",
        "\n",
        "# Handle potential NaN values in the feature set\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(feature_df)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and predict with Gradient Boosting Classifier\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "gbm.fit(X_train, y_train)\n",
        "y_pred_gbm = gbm.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_gbm)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_gbm, average='binary')\n",
        "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKUXF80UmFQr"
      },
      "source": [
        "***APPLYING LOGISTIC REGRESSION MODEL ***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ezNcUBmFXn",
        "outputId": "b8550468-3bf2-4e14-9909-c1986743464e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.7276807980049875, Precision: 0.7279218415283669, Recall: 0.7276807980049875, F1 Score: 0.7277897140826657\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log_reg = log_reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "precision_log_reg, recall_log_reg, f1_score_log_reg, _ = precision_recall_fscore_support(y_test, y_pred_log_reg, average='weighted')\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_log_reg}, Precision: {precision_log_reg}, Recall: {recall_log_reg}, F1 Score: {f1_score_log_reg}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkibLglPqPMu"
      },
      "source": [
        "**APPLYING DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SbQ3bWHqPke",
        "outputId": "a2d386df-9694-4ac6-bc43-49f02509dc16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Accuracy: 0.6503740648379053, Precision: 0.651731920693249, Recall: 0.6503740648379053, F1 Score: 0.6508772423860919\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='weighted')\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt}, Precision: {precision_dt}, Recall: {recall_dt}, F1 Score: {f1_score_dt}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xXlJPX6quT5"
      },
      "source": [
        "**APPLYING SUPPORT VECTOR CLASSIFIER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l33x8cB-quaW",
        "outputId": "1cc5ab17-5048-40a5-f87e-be6280af871a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC Accuracy: 0.7092269326683291, Precision: 0.7119441938484935, Recall: 0.7092269326683291, F1 Score: 0.7098865232272593\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize Support Vector Classifier model\n",
        "svc_model = SVC(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "svc_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svc = svc_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='weighted')\n",
        "print(f\"SVC Accuracy: {accuracy_svc}, Precision: {precision_svc}, Recall: {recall_svc}, F1 Score: {f1_score_svc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RRHcNqdrTrT"
      },
      "source": [
        "**APPLYING RANDOM FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Hi7sQYrTz1",
        "outputId": "69f1dadd-1e1b-41a2-a8d8-8f9a6af859cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.7092269326683291, Precision: 0.7090806988613638, Recall: 0.7092269326683291, F1 Score: 0.7091493947637251\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest Classifier model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='weighted')\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1 Score: {f1_score_rf}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LEFsuNOrf8K"
      },
      "source": [
        "**APPLYING XG BOOST MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tipBvP4Xan0_",
        "outputId": "3f200209-2285-43f6-8cdf-c6c24a478278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.68428927680798, Precision: 0.6388308977035491, Recall: 0.6807563959955506, F1 Score: 0.6591276252019387\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb}, Precision: {precision_xgb}, Recall: {recall_xgb}, F1 Score: {f1_score_xgb}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUl3sAeYsTL9"
      },
      "source": [
        "**APPLYING LGBM MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VupI_BumbCgi",
        "outputId": "a5a27a1f-eacb-49f3-c986-b5aabebcce0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056549 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3378\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 1382\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "LightGBM Accuracy: 0.6982543640897756, Precision: 0.653125, Recall: 0.6974416017797553, F1 Score: 0.6745562130177515\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suppose X_train, X_test, y_train, y_test are already defined and preprocessed\n",
        "\n",
        "# Initialize LightGBM classifier\n",
        "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "lgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lgb = lgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
        "precision_lgb, recall_lgb, f1_score_lgb, _ = precision_recall_fscore_support(y_test, y_pred_lgb, average='binary')\n",
        "\n",
        "# Print the results\n",
        "print(f\"LightGBM Accuracy: {accuracy_lgb}, Precision: {precision_lgb}, Recall: {recall_lgb}, F1 Score: {f1_score_lgb}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "stNiswQiotqq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "N0DwDsE2uCaK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "6t1oYKCeuIYH"
      },
      "outputs": [],
      "source": [
        "###############################################################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GI8qRiDuEMz"
      },
      "source": [
        "**STACKING MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcSrkBKCbbHj",
        "outputId": "cbcefcf1-0fa2-407a-c257-12e45c9c89c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059524 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3378\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 1382\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "[LightGBM] [Info] Number of positive: 3005, number of negative: 3409\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.056092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2811\n",
            "[LightGBM] [Info] Number of data points in the train set: 6414, number of used features: 1138\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468506 -> initscore=-0.126141\n",
            "[LightGBM] [Info] Start training from score -0.126141\n",
            "[LightGBM] [Info] Number of positive: 3005, number of negative: 3409\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036932 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2829\n",
            "[LightGBM] [Info] Number of data points in the train set: 6414, number of used features: 1146\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468506 -> initscore=-0.126141\n",
            "[LightGBM] [Info] Start training from score -0.126141\n",
            "[LightGBM] [Info] Number of positive: 3004, number of negative: 3410\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036890 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2808\n",
            "[LightGBM] [Info] Number of data points in the train set: 6414, number of used features: 1139\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468350 -> initscore=-0.126768\n",
            "[LightGBM] [Info] Start training from score -0.126768\n",
            "[LightGBM] [Info] Number of positive: 3005, number of negative: 3410\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036539 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2795\n",
            "[LightGBM] [Info] Number of data points in the train set: 6415, number of used features: 1137\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468433 -> initscore=-0.126435\n",
            "[LightGBM] [Info] Start training from score -0.126435\n",
            "[LightGBM] [Info] Number of positive: 3005, number of negative: 3410\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036469 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2817\n",
            "[LightGBM] [Info] Number of data points in the train set: 6415, number of used features: 1137\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468433 -> initscore=-0.126435\n",
            "[LightGBM] [Info] Start training from score -0.126435\n",
            "Stacking Model Accuracy: 0.6932668329177057, Precision: 0.6488469601677149, Recall: 0.6885428253615128, F1 Score: 0.6681057744198596\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Assume X_train, X_test, y_train, y_test are already prepared\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    ('xgb', xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)),\n",
        "    ('lgb', lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42))\n",
        "]\n",
        "\n",
        "# Define the meta-model\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "# Initialize the Stacking Classifier\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
        "\n",
        "# Train the stacking model\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_stack = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred_stack)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred_stack, average='binary')\n",
        "\n",
        "# Print the results\n",
        "print(f\"Stacking Model Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js1QZz7Fwk2h"
      },
      "source": [
        "**K-FOLD MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ij3EW95cbZX",
        "outputId": "43b73acb-2824-4c14-a1c9-b8ae123bd51c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-68-18c003476beb>:43: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['cultural_origin'] = clean_data['name'].apply(infer_cultural_origin)\n",
            "<ipython-input-68-18c003476beb>:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['ends_with_vowel'] = clean_data['name'].apply(ends_with_vowel)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 2098, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 2098, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 2098, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 2098, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.66%\n",
            "Average Precision: nan%\n",
            "Average Recall: nan%\n",
            "Average F1 Score: nan%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1954, in precision_score\n",
            "    p, _, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 2098, in recall_score\n",
            "    _, r, _, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:794: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 115, in __call__\n",
            "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 282, in _score\n",
            "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1146, in f1_score\n",
            "    return fbeta_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1287, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1573, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 1382, in _check_set_wise_labels\n",
            "    raise ValueError(\n",
            "ValueError: pos_label=1 is not a valid label. It should be one of ['female', 'male']\n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from scipy.sparse import hstack\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('gender-classifier.csv', encoding='latin-1')\n",
        "\n",
        "# Filter out entries with low confidence in gender identification\n",
        "filtered_data = data[(data['gender:confidence'] > 0.9) & (data['gender'].isin(['male', 'female']))]\n",
        "\n",
        "# Select only the 'name' and 'gender' columns for our task\n",
        "clean_data = filtered_data[['name', 'gender']]\n",
        "\n",
        "# Vectorize the names into n-gram features\n",
        "vectorizer = CountVectorizer(analyzer='char', ngram_range=(1, 2))\n",
        "ngram_features = vectorizer.fit_transform(clean_data['name'])\n",
        "\n",
        "# Create feature DataFrame from n-grams\n",
        "feature_df = pd.DataFrame(ngram_features.todense(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Function to infer cultural origin (needs to be defined or included)\n",
        "# def infer_cultural_origin(name):\n",
        "#     name = name.lower()\n",
        "#     if any(x in name for x in ['x', 'q', 'zh', 'wang', 'li']):\n",
        "#         return 'East Asian'\n",
        "#     elif any(x in name for x in ['patel', 'kumar', 'singh']):\n",
        "#         return 'South Asian'\n",
        "#     elif any(x in name for x in ['smith', 'johnson', 'williams']):\n",
        "#         return 'Western'\n",
        "#     else:\n",
        "#         return 'Other'\n",
        "\n",
        "# Function to check if the name ends with a vowel\n",
        "def ends_with_vowel(name):\n",
        "    return 1 if name[-1].lower() in 'aeiou' else 0\n",
        "\n",
        "# Apply functions for additional features\n",
        "clean_data['cultural_origin'] = clean_data['name'].apply(infer_cultural_origin)\n",
        "clean_data['ends_with_vowel'] = clean_data['name'].apply(ends_with_vowel)\n",
        "# cultural_dummies = pd.get_dummies(clean_data['cultural_origin'], prefix='origin')\n",
        "\n",
        "# Combine all features\n",
        "feature_df = feature_df.join(cultural_dummies)\n",
        "feature_df['ends_with_vowel'] = clean_data['ends_with_vowel'].values\n",
        "\n",
        "# Handle potential NaN values in the feature set\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_imputed = imputer.fit_transform(feature_df)\n",
        "\n",
        "# Prepare target variable\n",
        "labels = clean_data['gender'].values\n",
        "\n",
        "# Setup KFold cross-validation\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize the Gradient Boosting Classifier\n",
        "gbm = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Specify the scoring metrics\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_results = cross_validate(gbm, X_imputed, labels, cv=kfold, scoring=scoring)\n",
        "\n",
        "# Calculate average scores\n",
        "average_accuracy = np.mean(cv_results['test_accuracy'])\n",
        "average_precision = np.mean(cv_results['test_precision'])\n",
        "average_recall = np.mean(cv_results['test_recall'])\n",
        "average_f1_score = np.mean(cv_results['test_f1'])\n",
        "\n",
        "# Print the results\n",
        "print(f\"Average Accuracy: {average_accuracy:.2f}%\")\n",
        "print(f\"Average Precision: {average_precision:.2f}%\")\n",
        "print(f\"Average Recall: {average_recall:.2f}%\")\n",
        "print(f\"Average F1 Score: {average_f1_score:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "FBf85gHPfCIb"
      },
      "outputs": [],
      "source": [
        "# from metaphone import doublemetaphone\n",
        "\n",
        "# # Example usage\n",
        "# name = \"example\"\n",
        "# print(doublemetaphone(name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbFUWdh4ow4F",
        "outputId": "0ccf6c2a-f9b6-42dd-b545-e382eeac9354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting metaphone\n",
            "  Downloading Metaphone-0.6.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: metaphone\n",
            "  Building wheel for metaphone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for metaphone: filename=Metaphone-0.6-py3-none-any.whl size=13902 sha256=2cb7d8847ee6a31d5db4f612bdd6b2978d08e93a682597c1dc640d5e91d1aa5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/dd/1d/6cdd346605db62bde1f60954155e9ce48f4681c243f265b704\n",
            "Successfully built metaphone\n",
            "Installing collected packages: metaphone\n",
            "Successfully installed metaphone-0.6\n"
          ]
        }
      ],
      "source": [
        "pip install metaphone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVanObTZx0jk"
      },
      "source": [
        "METAPHONE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAsjNEPxfHdl",
        "outputId": "37077db0-de76-4362-a980-7e6e04543829"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-71-0bef33b5f79f>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['metaphone_code'] = clean_data['name'].apply(generate_metaphone_code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5386533665835411, Precision: 0.6875, Recall: 0.011815252416756176, F1 Score: 0.023231256599788808\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from metaphone import doublemetaphone\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('gender-classifier.csv', encoding='latin-1')\n",
        "\n",
        "# Filter out entries with low confidence in gender identification\n",
        "filtered_data = data[(data['gender:confidence'] > 0.9) & (data['gender'].isin(['male', 'female']))]\n",
        "\n",
        "# Select only the 'name' and 'gender' columns for our task\n",
        "clean_data = filtered_data[['name', 'gender']]\n",
        "\n",
        "def generate_metaphone_code(name):\n",
        "    return doublemetaphone(name)[0]  # Using only the primary encoding\n",
        "\n",
        "# Apply Metaphone encoding to names\n",
        "clean_data['metaphone_code'] = clean_data['name'].apply(generate_metaphone_code)\n",
        "\n",
        "# Convert Metaphone codes to one-hot encoding\n",
        "metaphone_dummies = pd.get_dummies(clean_data['metaphone_code'], prefix='meta')\n",
        "\n",
        "# Drop the original 'name' and 'metaphone_code' columns to avoid using raw string data\n",
        "clean_data = clean_data.drop(['name', 'metaphone_code'], axis=1)\n",
        "clean_data = pd.concat([clean_data, metaphone_dummies], axis=1)\n",
        "\n",
        "# Encode the target variable 'gender'\n",
        "label_encoder = LabelEncoder()\n",
        "clean_data['gender'] = label_encoder.fit_transform(clean_data['gender'])\n",
        "\n",
        "# Prepare features and labels for training\n",
        "X = clean_data.drop('gender', axis=1)\n",
        "y = clean_data['gender']\n",
        "\n",
        "# Split the dataset ensuring no data leakage\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize and train the classifier\n",
        "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}\")\n",
        "\n",
        "\n",
        "# # Split the dataset\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Initialize and train the classifier\n",
        "# classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "# classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Predict and evaluate\n",
        "# y_pred = classifier.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "# # Output the results\n",
        "# print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE6-jcLyyZDd"
      },
      "source": [
        "APPLYING LOGISTIC REGRESSION MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY4J7vGDykqM",
        "outputId": "83fc0c20-b71d-44e5-9c76-1df98078b3eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Accuracy: 0.5531172069825436, Precision: 0.7215189873417721, Recall: 0.061224489795918366, F1 Score: 0.11287128712871287\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Split the dataset ensuring no data leakage\n",
        "X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "log_reg_model.fit(X_train_log, y_train_log)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_log_reg = log_reg_model.predict(X_test_log)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_log_reg = accuracy_score(y_test_log, y_pred_log_reg)\n",
        "precision_log_reg, recall_log_reg, f1_score_log_reg, _ = precision_recall_fscore_support(y_test_log, y_pred_log_reg, average='binary')\n",
        "print(f\"Logistic Regression Accuracy: {accuracy_log_reg}, Precision: {precision_log_reg}, Recall: {recall_log_reg}, F1 Score: {f1_score_log_reg}\")\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# # Initialize Logistic Regression model\n",
        "# log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# # Fit the model\n",
        "# log_reg_model.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on the test set\n",
        "# y_pred_log_reg = log_reg_model.predict(X_test)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
        "# precision_log_reg, recall_log_reg, f1_score_log_reg, _ = precision_recall_fscore_support(y_test, y_pred_log_reg, average='binary')\n",
        "# print(f\"Logistic Regression Accuracy: {accuracy_log_reg}, Precision: {precision_log_reg}, Recall: {recall_log_reg}, F1 Score: {f1_score_log_reg}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Waa20qjV9LeD"
      },
      "source": [
        "**APPLYING DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHQHewpI9LoL",
        "outputId": "511ae40b-afb4-4176-8773-f5c776d5d75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Accuracy: 0.5531172069825436, Precision: 0.7215189873417721, Recall: 0.061224489795918366, F1 Score: 0.11287128712871287\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Split the dataset ensuring no data leakage\n",
        "X_train_dt, X_test_dt, y_train_dt, y_test_dt = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize Decision Tree model\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "dt_model.fit(X_train_dt, y_train_dt)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_dt = dt_model.predict(X_test_dt)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_dt = accuracy_score(y_test_dt, y_pred_dt)\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test_dt, y_pred_dt, average='binary')\n",
        "print(f\"Decision Tree Accuracy: {accuracy_dt}, Precision: {precision_dt}, Recall: {recall_dt}, F1 Score: {f1_score_dt}\")\n",
        "\n",
        "\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# # Initialize Decision Tree model\n",
        "# dt_model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# # Fit the model\n",
        "# dt_model.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on the test set\n",
        "# y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# # Evaluate the model\n",
        "# accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "# precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "# print(f\"Decision Tree Accuracy: {accuracy_dt}, Precision: {precision_dt}, Recall: {recall_dt}, F1 Score: {f1_score_dt}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baW4WD4F9MBA"
      },
      "source": [
        "APPLYING SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koMEGScy9MId",
        "outputId": "3c95dd96-8ce5-4021-8b34-538f5e32ec14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVC Accuracy: 0.5531172069825436, Precision: 0.7215189873417721, Recall: 0.061224489795918366, F1 Score: 0.11287128712871287\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize Support Vector Classifier model\n",
        "svc_model = SVC(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "svc_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_svc = svc_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "print(f\"SVC Accuracy: {accuracy_svc}, Precision: {precision_svc}, Recall: {recall_svc}, F1 Score: {f1_score_svc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2tYB39i9Nim"
      },
      "source": [
        "APPLYING RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp5YZicf9Nr-",
        "outputId": "3ae78f66-4e5b-4bae-f8cd-4eadb1eb3e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy: 0.5531172069825436, Precision: 0.7215189873417721, Recall: 0.061224489795918366, F1 Score: 0.11287128712871287\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest Classifier model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "print(f\"Random Forest Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1 Score: {f1_score_rf}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dwROTP79OI7"
      },
      "source": [
        "**APPLYING XG BOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crd-fTpn9OfX",
        "outputId": "3c79d705-115f-4800-9bd1-0c836da4f254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost Accuracy: 0.5356608478802992, Precision: 0.5, Recall: 0.0010741138560687433, F1 Score: 0.0021436227224008574\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "print(f\"XGBoost Accuracy: {accuracy_xgb}, Precision: {precision_xgb}, Recall: {recall_xgb}, F1 Score: {f1_score_xgb}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2nz8j7z9On0"
      },
      "source": [
        "APPLYING LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxEMiKN69Owr",
        "outputId": "ee39e9e4-2f5b-493c-9abb-4c730b5e3bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 3724, number of negative: 4294\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 0\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.464455 -> initscore=-0.142420\n",
            "[LightGBM] [Info] Start training from score -0.142420\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "LGBM Accuracy: 0.5356608478802992, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Split the dataset ensuring no data leakage\n",
        "X_train_lgbm, X_test_lgbm, y_train_lgbm, y_test_lgbm = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize LGBM model\n",
        "lgbm_model = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "lgbm_model.fit(X_train_lgbm, y_train_lgbm)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_lgbm = lgbm_model.predict(X_test_lgbm)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy_lgbm = accuracy_score(y_test_lgbm, y_pred_lgbm)\n",
        "precision_lgbm, recall_lgbm, f1_score_lgbm, _ = precision_recall_fscore_support(y_test_lgbm, y_pred_lgbm, average='binary')\n",
        "print(f\"LGBM Accuracy: {accuracy_lgbm}, Precision: {precision_lgbm}, Recall: {recall_lgbm}, F1 Score: {f1_score_lgbm}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI-8oixTC0of",
        "outputId": "c497b7eb-d175-4f24-a9b3-04c23543d543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gender_guesser\n",
            "  Downloading gender_guesser-0.4.0-py2.py3-none-any.whl (379 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m379.3/379.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gender_guesser\n",
            "Successfully installed gender_guesser-0.4.0\n"
          ]
        }
      ],
      "source": [
        "pip install gender_guesser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhUolkY59O4g"
      },
      "source": [
        "**Gender guesser**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krWB5Unqhlme",
        "outputId": "a75f37a7-83f6-4873-a823-b27b9ad45022"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5516209476309227, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-79-2be6ed5d65a3>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['predicted_gender'] = clean_data['name'].apply(get_gender)\n",
            "<ipython-input-79-2be6ed5d65a3>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  clean_data['gender'] = label_encoder.fit_transform(clean_data['gender'])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import gender_guesser.detector as gender\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('gender-classifier.csv', encoding='latin-1')\n",
        "\n",
        "# Filter out entries with low confidence in gender identification\n",
        "filtered_data = data[(data['gender:confidence'] > 0.9) & (data['gender'].isin(['male', 'female']))]\n",
        "\n",
        "# Select only the 'name' and 'gender' columns for our task\n",
        "clean_data = filtered_data[['name', 'gender']]\n",
        "\n",
        "detector = gender.Detector(case_sensitive=False)\n",
        "\n",
        "# Function to predict gender based username\n",
        "def get_gender(name):\n",
        "    first_name = name.split()[0] \n",
        "    return detector.get_gender(first_name)\n",
        "\n",
        "# Apply gender prediction\n",
        "clean_data['predicted_gender'] = clean_data['name'].apply(get_gender)\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "clean_data['gender'] = label_encoder.fit_transform(clean_data['gender'])\n",
        "\n",
        "# One-hot encode the predicted gender\n",
        "gender_dummies = pd.get_dummies(clean_data['predicted_gender'], prefix='gender')\n",
        "clean_data = pd.concat([clean_data, gender_dummies], axis=1)\n",
        "\n",
        "# Prepare features and labels\n",
        "X = clean_data.drop(['name', 'gender', 'predicted_gender'], axis=1)\n",
        "y = clean_data['gender']\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a classifier\n",
        "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Prediction and evaluation\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1_score}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDivBnbKDA6K"
      },
      "source": [
        "LOGISTIC REGRESSION MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLgDkV2WDBQT",
        "outputId": "2c54c4e0-3413-49eb-94ed-2140a501e00d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression:\n",
            "Accuracy: 0.5516209476309227, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Initialize the classifier\n",
        "logistic_regression = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lr = logistic_regression.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr, recall_lr, f1_score_lr, _ = precision_recall_fscore_support(y_test, y_pred_lr, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(\"Logistic Regression:\")\n",
        "print(f\"Accuracy: {accuracy_lr}, Precision: {precision_lr}, Recall: {recall_lr}, F1 Score: {f1_score_lr}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceSaajz9DBls"
      },
      "source": [
        "**DECISION TREE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75wxCxiHDByq",
        "outputId": "89372468-8c7c-4f95-8729-781547e821de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree:\n",
            "Accuracy: 0.5516209476309227, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize the classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt, recall_dt, f1_score_dt, _ = precision_recall_fscore_support(y_test, y_pred_dt, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(\"Decision Tree:\")\n",
        "print(f\"Accuracy: {accuracy_dt}, Precision: {precision_dt}, Recall: {recall_dt}, F1 Score: {f1_score_dt}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi9qWCVYDB53"
      },
      "source": [
        "SUPPORT VECTOR CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3PbXo4QDCAr",
        "outputId": "62b88685-7123-43a7-811a-8423ed4c70f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Support Vector Classifier (SVC):\n",
            "Accuracy: 0.5516209476309227, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Initialize the classifier\n",
        "svc = SVC(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_svc = svc.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
        "precision_svc, recall_svc, f1_score_svc, _ = precision_recall_fscore_support(y_test, y_pred_svc, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(\"Support Vector Classifier (SVC):\")\n",
        "print(f\"Accuracy: {accuracy_svc}, Precision: {precision_svc}, Recall: {recall_svc}, F1 Score: {f1_score_svc}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqTbrlSRDCH8"
      },
      "source": [
        "RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cP5CreoDCR4",
        "outputId": "e343d60f-b588-418f-b3e5-7f0145fd5556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest:\n",
            "Accuracy: 0.5516209476309227, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the classifier\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf, recall_rf, f1_score_rf, _ = precision_recall_fscore_support(y_test, y_pred_rf, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(\"Random Forest:\")\n",
        "print(f\"Accuracy: {accuracy_rf}, Precision: {precision_rf}, Recall: {recall_rf}, F1 Score: {f1_score_rf}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiLrfKTQDCss"
      },
      "source": [
        "XG BOOST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MUjmh14DCz9",
        "outputId": "101c870d-b636-44bb-a154-d6a058d33839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XGBoost:\n",
            "Accuracy: 0.5516209476309227, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "# Initialize the classifier\n",
        "xgboost = xgb.XGBClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "xgboost.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_xgb = xgboost.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb, recall_xgb, f1_score_xgb, _ = precision_recall_fscore_support(y_test, y_pred_xgb, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(\"XGBoost:\")\n",
        "print(f\"Accuracy: {accuracy_xgb}, Precision: {precision_xgb}, Recall: {recall_xgb}, F1 Score: {f1_score_xgb}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcaneS5_DC7g"
      },
      "source": [
        "LIGHT GBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ZtIPPqDDBf",
        "outputId": "3b616142-4582-4c5e-b8c7-c8dd39f0c7fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
            "[LightGBM] [Info] Number of positive: 3756, number of negative: 4262\n",
            "[LightGBM] [Info] Total Bins 0\n",
            "[LightGBM] [Info] Number of data points in the train set: 8018, number of used features: 0\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.468446 -> initscore=-0.126384\n",
            "[LightGBM] [Info] Start training from score -0.126384\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "LightGBM:\n",
            "Accuracy: 0.5516209476309227, Precision: 0.0, Recall: 0.0, F1 Score: 0.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "# Initialize the classifier\n",
        "lightgbm = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "lightgbm.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lgbm = lightgbm.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy_lgbm = accuracy_score(y_test, y_pred_lgbm)\n",
        "precision_lgbm, recall_lgbm, f1_score_lgbm, _ = precision_recall_fscore_support(y_test, y_pred_lgbm, average='binary')\n",
        "\n",
        "# Output the results\n",
        "print(\"LightGBM:\")\n",
        "print(f\"Accuracy: {accuracy_lgbm}, Precision: {precision_lgbm}, Recall: {recall_lgbm}, F1 Score: {f1_score_lgbm}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKykb22vDDJE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "fTopsK81DDRH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
